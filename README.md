# Projeto-Final---Aplica-o-de-Algoritmos-de-Machine-Learning-em-problemas-reais

# üåßÔ∏è Previs√£o de Chuva com Machine Learning ‚Äì weatherAUS

Este projeto tem como objetivo construir e comparar modelos de aprendizado supervisionado para prever se **vai chover amanh√£** (`RainTomorrow`) com base em vari√°veis meteorol√≥gicas hist√≥ricas fornecidas no dataset `weatherAUS.csv`.

---

## üìÅ Dataset

- **Fonte:** [Kaggle - Weather Dataset - Rattle Package](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package)
- **Descri√ß√£o:** Dados clim√°ticos de esta√ß√µes meteorol√≥gicas australianas contendo informa√ß√µes como temperatura, umidade, vento, press√£o, evapora√ß√£o e precipita√ß√£o.
- **Tarefa:** Classifica√ß√£o bin√°ria (`RainTomorrow`: Yes ou No)

---

## üéØ Objetivo

> Desenvolver um modelo preditivo que, com base em condi√ß√µes clim√°ticas observadas at√© o dia atual, estime se ir√° chover no pr√≥ximo dia.

---

## üß™ Algoritmos Utilizados

- üå≤ **Random Forest (com ajuste de hiperpar√¢metros)**
- ‚ö° **XGBoost**
- üìç **K-Nearest Neighbors (KNN)**

---

## üîç Etapas do Pipeline

1. **Carregamento do Dataset**
   - Leitura do arquivo CSV
2. **An√°lise Explorat√≥ria**
   - Gr√°ficos, boxplots, heatmaps de correla√ß√£o
   - Identifica√ß√£o de valores ausentes e outliers
3. **Pr√©-processamento**
   - Remo√ß√£o de colunas com mais de 30% de valores ausentes
   - Preenchimento de valores nulos (mediana/mode)
   - Extra√ß√£o de `Month` e `Year` da data
   - One-Hot Encoding em vari√°veis categ√≥ricas
   - Detec√ß√£o e poss√≠vel remo√ß√£o de outliers com IQR
4. **Divis√£o dos Dados**
   - Treino e teste com `train_test_split`
   - Normaliza√ß√£o **apenas para o KNN**
5. **Modelagem**
   - **Random Forest:** ajuste fino com `GridSearchCV`
   - **XGBoost:** treinamento direto sem redu√ß√£o de dimensionalidade
   - **KNN:** aplicado com dados normalizados
6. **Avalia√ß√£o dos Modelos**
   - Matriz de confus√£o
   - Precision, Recall, F1-score
   - Curva ROC e AUC
7. **Compara√ß√£o Final**
   - An√°lise dos trade-offs entre os modelos para aplica√ß√£o real

---

## üìä Principais Resultados

| Modelo         | Recall (Chuva) | F1-score (Chuva) | Observa√ß√£o                        |
|----------------|----------------|------------------|-----------------------------------|
| Random Forest  | 0.49           | 0.60             | Conservador (erra menos alarmes) |
| **XGBoost**    | **0.55**       | **0.63**         | **Melhor para prever chuva**     |
| KNN            | 0.31           | 0.42             | Desempenho fraco, n√£o recomendado|

---

## üåæ Aplica√ß√£o na Agricultura

- O **recall da classe positiva ("True")** foi usado como crit√©rio principal para escolha do modelo mais apropriado.
- O **XGBoost** foi o mais indicado, pois consegue **detectar mais dias em que realmente chove**, mesmo gerando alguns falsos alarmes, o que √© prefer√≠vel em contextos agr√≠colas.

---

## üìå Conclus√µes

- ‚ùå Redu√ß√µes de dimensionalidade como **PCA** ou **LDA** **pioraram o desempenho**, pois XGBoost j√° lida bem com dados brutos.
- ‚úÖ A aplica√ß√£o de **valida√ß√£o cruzada com `GridSearchCV` no Random Forest** trouxe melhorias moderadas.
- ‚úÖ A **normaliza√ß√£o foi aplicada apenas no KNN**, que √© sens√≠vel √† escala.
- üîç M√©tricas como **Recall** e **F1-score** foram priorizadas em vez da acur√°cia, devido ao desbalanceamento entre as classes.

---

## üöÄ Poss√≠veis Extens√µes

- Aplicar **SMOTE** para balancear as classes
- Ajustar o **threshold de decis√£o** do XGBoost para priorizar recall
- Exportar o modelo final (`joblib`, `pickle`) para uso em APIs
- Deploy com **Streamlit**, **Flask** ou **FastAPI**

---

## üß† Autor

**Adriano Pedro Couto dos Santos**  
Estudo de previs√£o clim√°tica com aplica√ß√£o em ci√™ncia de dados.  
Orientado a aplica√ß√µes reais como agricultura e tomada de decis√£o estrat√©gica.

---

## üìé Licen√ßa

Este projeto √© livre para uso educacional e pessoal. Para usos comerciais, entre em contato.

